{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_v2_DataAug.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "utCBcPcIebjX"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def __Conv(data, n=10):\n",
        "    x = data[1:].astype(np.float32) / 255\n",
        "    y = np.array([int(i == data[0]) for i in range(n)]).astype(np.float32)\n",
        "    return (x, y)\n",
        "\n",
        "def Conv(data):\n",
        "    ret = [*data]\n",
        "    for i in range(len(ret)):\n",
        "        ret[i] = __Conv(ret[i])\n",
        "    return ret\n",
        "\n",
        "def load_data():\n",
        "    mnist = keras.datasets.mnist\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    x_train = x_train.reshape(-1, 784)\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    x_test = x_test.reshape(-1, 784)\n",
        "    y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "    train_data = np.concatenate((y_train, x_train), axis = 1)\n",
        "    test_data = np.concatenate((y_test, x_test), axis = 1)\n",
        "    train_data = Conv(train_data)\n",
        "    test_data  = Conv(test_data)\n",
        "\n",
        "    return (train_data, test_data)\n",
        "\n",
        "train_data, test_data = load_data()\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu1Jb5jpumYj"
      },
      "source": [
        "class Sigmoid:\n",
        "    def __call__(self, x):\n",
        "        return 1. / (1. + np.exp(-x))\n",
        "\n",
        "    def deriv(self, x):\n",
        "        return self(x) * (1 - self(x))\n",
        "\n",
        "\n",
        "class ReLU:\n",
        "    def __call__(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def deriv(self, x):\n",
        "        return (x > 0).astype(np.float32)\n",
        "\n",
        "\n",
        "class LeakyReLU:\n",
        "    def __call__(self, x):\n",
        "        ret = x\n",
        "        ret[ret < 0] *= 0.01\n",
        "        return ret.astype(np.float32)\n",
        "\n",
        "    def deriv(self, x):\n",
        "        ret = x\n",
        "        ret[ret < 0] = -0.01\n",
        "        ret[ret > 0] = 1.\n",
        "        return ret.astype(np.float32)\n",
        "\n",
        "\n",
        "class MSE:\n",
        "    def __call__(self, res, y):\n",
        "        return sum((i - j) * (i - j) for i, j in zip(res, y))\n",
        "\n",
        "    def deriv(self, res, y, z, activation_f):\n",
        "        return (res - y) * activation_f.deriv(z)\n",
        "\n",
        "\n",
        "class CrossEntropy:\n",
        "    def __call__(self, res, y):\n",
        "        return np.sum(np.nan_to_num(-y * np.log(a) - (1 - y) * np.log(1 - a)))\n",
        "\n",
        "    def deriv(self, res, y, z, activation_f):\n",
        "        return res - y\n",
        "\n",
        "\n",
        "class Network:\n",
        "    def __init__(self, shape, activation_f=ReLU(), cost_f=CrossEntropy()):\n",
        "        np.random.seed(2048)\n",
        "        self.shape = shape\n",
        "        self.w = [np.random.uniform(-(6 / x) ** 0.5, (6 / x) ** 0.5, x * y).reshape(y, x) for x, y in\n",
        "                  zip(shape[:-1], shape[1:])]\n",
        "        self.b = [np.random.uniform(-(6 / x) ** 0.5, (6 / x) ** 0.5, 1 * y).reshape(y, 1) for x, y in\n",
        "                  zip(shape[:-1], shape[1:])]\n",
        "        self.activation_f = activation_f\n",
        "        self.cost_f = cost_f\n",
        "\n",
        "    def forward(self, x):\n",
        "        ret = x.reshape(-1, 1)\n",
        "        for w, b in zip(self.w, self.b):\n",
        "            ret = self.activation_f(np.dot(w, ret) + b)\n",
        "        return ret.reshape(-1)\n",
        "\n",
        "    def backward(self, _x, _y):\n",
        "        dw = [np.zeros(w.shape) for w in self.w]\n",
        "        db = [np.zeros(b.shape) for b in self.b]\n",
        "        x, y = _x.reshape(-1, 1), _y.reshape(-1, 1)\n",
        "        a, z = [x], []\n",
        "\n",
        "        for w, b in zip(self.w, self.b):\n",
        "            x = np.dot(w, x) + b\n",
        "            z.append(x)\n",
        "            x = self.activation_f(x)\n",
        "            a.append(x)\n",
        "\n",
        "        dz = self.cost_f.deriv(a[-1], y, z[-1], self.activation_f)\n",
        "        dw[-1] = np.dot(dz, a[-2].transpose())\n",
        "        db[-1] = dz\n",
        "\n",
        "        for i in range(2, len(self.shape)):\n",
        "            dz = np.dot(self.w[-(i - 1)].transpose(), dz) * self.activation_f.deriv(z[-i])\n",
        "            dw[-i] = np.dot(dz, a[-(i + 1)].transpose())\n",
        "            db[-i] = dz\n",
        "\n",
        "        return (dw, db)\n",
        "\n",
        "    def update(self, batch, lr, lmbda, n):\n",
        "        dw = [np.zeros(w.shape) for w in self.w]\n",
        "        db = [np.zeros(b.shape) for b in self.b]\n",
        "\n",
        "        for x, y in batch:\n",
        "            _dw, _db = self.backward(x, y)\n",
        "            dw = [w + _w for w, _w in zip(dw, _dw)]\n",
        "            db = [b + _b for b, _b in zip(db, _db)]\n",
        "\n",
        "        self.w = [(1 - lr * (lmbda / n)) * w - (lr / len(batch)) * _w for w, _w in zip(self.w, dw)]\n",
        "        self.b = [b - (lr / len(batch)) * _b for b, _b in zip(self.b, db)]\n",
        "\n",
        "    def SGD(self, epochs, batch_size, lr, lmbda, train_data, data_per_epoch, lr_scheduler=None, test_data=None):\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            np.random.RandomState(epoch).shuffle(train_data)\n",
        "            batchs = [train_data[i:i + batch_size] for i in range(0, data_per_epoch, batch_size)]\n",
        "            for batch in batchs: self.update(batch, lr, lmbda, len(train_data))\n",
        "            if test_data:\n",
        "                print(f\"Epoch : {epoch}, Evaluate : {self.evaluate(test_data)} / {len(test_data)}\")\n",
        "            else:\n",
        "                print(f\"Epoch : {epoch}\")\n",
        "            if lr_scheduler:\n",
        "                lr = lr_scheduler(lr, epoch)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        ret = sum(int(np.argmax(self.forward(x)) == np.argmax(y)) for x, y in test_data)\n",
        "        return ret\n",
        "\n",
        "    def Calc(self, x):\n",
        "        y = self.forward(x)\n",
        "        return np.argmax(y)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU_39vLIS4Iw",
        "outputId": "f197e44e-5c42-4894-e22e-0346a16275da"
      },
      "source": [
        "def __DataAugmentation(x, d):\n",
        "    dx = [0, -1, 0, 1]\n",
        "    dy = [1, 0, -1, 0]\n",
        "    x = x.reshape(28, 28)\n",
        "    ret = np.zeros(x.shape)\n",
        "    for i in range(28):\n",
        "        for j in range(28):\n",
        "            nx = i + dx[d]\n",
        "            ny = j + dy[d]\n",
        "            if nx < 0 or nx >= 28 or ny < 0 or ny >= 28: continue\n",
        "            ret[nx][ny] = x[i][j]\n",
        "    return ret.reshape(-1)\n",
        "\n",
        "def DataAugmentation(data):\n",
        "    n = len(data)\n",
        "    for i in range(n):\n",
        "        for j in range(4):\n",
        "            data.append((\n",
        "                __DataAugmentation(data[i][0], j), data[i][1]\n",
        "            ))\n",
        "    return data\n",
        "\n",
        "train_data = DataAugmentation(train_data)\n",
        "print(len(train_data))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJJfnmZIPCBh",
        "outputId": "df93eb9d-e635-41dd-c7c0-db8d40729f22"
      },
      "source": [
        "N = Network([784, 28, 28, 10])\n",
        "scheduler = lambda lr, epoch: lr * (1.0 if (epoch + 1) % 30 else 0.5)\n",
        "N.SGD(50, 10, 0.03, 0.1, train_data, 50000, lr_scheduler = scheduler, test_data = test_data)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1, Evaluate : 9278 / 10000\n",
            "Epoch : 2, Evaluate : 9449 / 10000\n",
            "Epoch : 3, Evaluate : 9508 / 10000\n",
            "Epoch : 4, Evaluate : 9559 / 10000\n",
            "Epoch : 5, Evaluate : 9562 / 10000\n",
            "Epoch : 6, Evaluate : 9576 / 10000\n",
            "Epoch : 7, Evaluate : 9608 / 10000\n",
            "Epoch : 8, Evaluate : 9632 / 10000\n",
            "Epoch : 9, Evaluate : 9641 / 10000\n",
            "Epoch : 10, Evaluate : 9621 / 10000\n",
            "Epoch : 11, Evaluate : 9633 / 10000\n",
            "Epoch : 12, Evaluate : 9638 / 10000\n",
            "Epoch : 13, Evaluate : 9651 / 10000\n",
            "Epoch : 14, Evaluate : 9640 / 10000\n",
            "Epoch : 15, Evaluate : 9671 / 10000\n",
            "Epoch : 16, Evaluate : 9663 / 10000\n",
            "Epoch : 17, Evaluate : 9661 / 10000\n",
            "Epoch : 18, Evaluate : 9668 / 10000\n",
            "Epoch : 19, Evaluate : 9680 / 10000\n",
            "Epoch : 20, Evaluate : 9683 / 10000\n",
            "Epoch : 21, Evaluate : 9680 / 10000\n",
            "Epoch : 22, Evaluate : 9676 / 10000\n",
            "Epoch : 23, Evaluate : 9699 / 10000\n",
            "Epoch : 24, Evaluate : 9689 / 10000\n",
            "Epoch : 25, Evaluate : 9698 / 10000\n",
            "Epoch : 26, Evaluate : 9703 / 10000\n",
            "Epoch : 27, Evaluate : 9698 / 10000\n",
            "Epoch : 28, Evaluate : 9704 / 10000\n",
            "Epoch : 29, Evaluate : 9685 / 10000\n",
            "Epoch : 30, Evaluate : 9737 / 10000\n",
            "Epoch : 31, Evaluate : 9726 / 10000\n",
            "Epoch : 32, Evaluate : 9735 / 10000\n",
            "Epoch : 33, Evaluate : 9739 / 10000\n",
            "Epoch : 34, Evaluate : 9737 / 10000\n",
            "Epoch : 35, Evaluate : 9725 / 10000\n",
            "Epoch : 36, Evaluate : 9728 / 10000\n",
            "Epoch : 37, Evaluate : 9729 / 10000\n",
            "Epoch : 38, Evaluate : 9744 / 10000\n",
            "Epoch : 39, Evaluate : 9744 / 10000\n",
            "Epoch : 40, Evaluate : 9743 / 10000\n",
            "Epoch : 41, Evaluate : 9738 / 10000\n",
            "Epoch : 42, Evaluate : 9735 / 10000\n",
            "Epoch : 43, Evaluate : 9740 / 10000\n",
            "Epoch : 44, Evaluate : 9748 / 10000\n",
            "Epoch : 45, Evaluate : 9728 / 10000\n",
            "Epoch : 46, Evaluate : 9733 / 10000\n",
            "Epoch : 47, Evaluate : 9728 / 10000\n",
            "Epoch : 48, Evaluate : 9743 / 10000\n",
            "Epoch : 49, Evaluate : 9747 / 10000\n",
            "Epoch : 50, Evaluate : 9750 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}