{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu1Jb5jpumYj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __call__(self, x):\n",
        "        return 1. / (1. + np.exp(-x))\n",
        "\n",
        "    def deriv(self, x):\n",
        "        return self(x) * (1 - self(x))\n",
        "\n",
        "\n",
        "class ReLU:\n",
        "    def __call__(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def deriv(self, x):\n",
        "        return (x > 0).astype(np.float32)\n",
        "\n",
        "\n",
        "class LeakyReLU:\n",
        "    def __call__(self, x):\n",
        "        ret = x\n",
        "        ret[ret < 0] *= 0.01\n",
        "        return ret.astype(np.float32)\n",
        "\n",
        "    def deriv(self, x):\n",
        "        ret = x\n",
        "        ret[ret < 0] = -0.01\n",
        "        ret[ret > 0] = 1.\n",
        "        return ret.astype(np.float32)\n",
        "\n",
        "\n",
        "class MSE:\n",
        "    def __call__(self, res, y):\n",
        "        return sum((i - j) * (i - j) for i, j in zip(res, y))\n",
        "\n",
        "    def deriv(self, res, y, z, activation_f):\n",
        "        return (res - y) * activation_f.deriv(z)\n",
        "\n",
        "\n",
        "class CrossEntropy:\n",
        "    def __call__(self, res, y):\n",
        "        return np.sum(np.nan_to_num(-y * np.log(a) - (1 - y) * np.log(1 - a)))\n",
        "\n",
        "    def deriv(self, res, y, z, activation_f):\n",
        "        return res - y\n",
        "\n",
        "\n",
        "class Network:\n",
        "    def __init__(self, shape, activation_f=ReLU(), cost_f=CrossEntropy()):\n",
        "        np.random.seed(2048)\n",
        "        self.shape = shape\n",
        "        self.w = [np.random.uniform(-(6 / x) ** 0.5, (6 / x) ** 0.5, x * y).reshape(y, x) for x, y in\n",
        "                  zip(shape[:-1], shape[1:])]\n",
        "        self.b = [np.random.uniform(-(6 / x) ** 0.5, (6 / x) ** 0.5, 1 * y).reshape(y, 1) for x, y in\n",
        "                  zip(shape[:-1], shape[1:])]\n",
        "        self.activation_f = activation_f\n",
        "        self.cost_f = cost_f\n",
        "\n",
        "    def forward(self, x):\n",
        "        ret = x.reshape(-1, 1)\n",
        "        for w, b in zip(self.w, self.b):\n",
        "            ret = self.activation_f(np.dot(w, ret) + b)\n",
        "        return ret.reshape(-1)\n",
        "\n",
        "    def backward(self, _x, _y):\n",
        "        dw = [np.zeros(w.shape) for w in self.w]\n",
        "        db = [np.zeros(b.shape) for b in self.b]\n",
        "        x, y = _x.reshape(-1, 1), _y.reshape(-1, 1)\n",
        "        a, z = [x], []\n",
        "\n",
        "        for w, b in zip(self.w, self.b):\n",
        "            x = np.dot(w, x) + b\n",
        "            z.append(x)\n",
        "            x = self.activation_f(x)\n",
        "            a.append(x)\n",
        "\n",
        "        dz = self.cost_f.deriv(a[-1], y, z[-1], self.activation_f)\n",
        "        dw[-1] = np.dot(dz, a[-2].transpose())\n",
        "        db[-1] = dz\n",
        "\n",
        "        for i in range(2, len(self.shape)):\n",
        "            dz = np.dot(self.w[-(i - 1)].transpose(), dz) * self.activation_f.deriv(z[-i])\n",
        "            dw[-i] = np.dot(dz, a[-(i + 1)].transpose())\n",
        "            db[-i] = dz\n",
        "\n",
        "        return (dw, db)\n",
        "\n",
        "    def update(self, batch, lr, lmbda, n):\n",
        "        dw = [np.zeros(w.shape) for w in self.w]\n",
        "        db = [np.zeros(b.shape) for b in self.b]\n",
        "\n",
        "        for x, y in batch:\n",
        "            _dw, _db = self.backward(x, y)\n",
        "            dw = [w + _w for w, _w in zip(dw, _dw)]\n",
        "            db = [b + _b for b, _b in zip(db, _db)]\n",
        "\n",
        "        self.w = [(1 - lr * (lmbda / n)) * w - (lr / len(batch)) * _w for w, _w in zip(self.w, dw)]\n",
        "        self.b = [b - (lr / len(batch)) * _b for b, _b in zip(self.b, db)]\n",
        "\n",
        "    def SGD(self, epochs, batch_size, lr, lmbda, train_data, test_data=None):\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            np.random.RandomState(epoch).shuffle(train_data)\n",
        "            batchs = [train_data[i:i + batch_size] for i in range(0, len(train_data), batch_size)]\n",
        "            for batch in batchs: self.update(batch, lr, lmbda, len(train_data))\n",
        "            if test_data:\n",
        "                print(f\"Epoch : {epoch}, Evaluate : {self.evaluate(test_data)} / {len(test_data)}\")\n",
        "            else:\n",
        "                print(f\"Epoch : {epoch}\")\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        ret = sum(int(np.argmax(self.forward(x)) == np.argmax(y)) for x, y in test_data)\n",
        "        return ret\n",
        "\n",
        "    def Calc(self, x):\n",
        "        y = self.forward(x)\n",
        "        return np.argmax(y)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vVQ5ytITzfN"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "train_data = np.concatenate((y_train, x_train), axis = 1)[:50000]\n",
        "test_data = np.concatenate((y_test, x_test), axis = 1)\n",
        "\n",
        "def __Conv(data, n=10):\n",
        "    x = data[1:].astype(np.float32) / 255\n",
        "    y = np.array([int(i == data[0]) for i in range(n)]).astype(np.float32)\n",
        "    return (x, y)\n",
        "\n",
        "def Conv(data):\n",
        "    ret = [*data]\n",
        "    for i in range(len(ret)):\n",
        "        ret[i] = __Conv(ret[i])\n",
        "    return ret\n",
        "\n",
        "train_data = Conv(train_data)\n",
        "test_data  = Conv(test_data)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJJfnmZIPCBh",
        "outputId": "d92be2cc-96cb-49a8-af8e-26a06cb0e816"
      },
      "source": [
        "N = Network([784, 28, 28, 10])\n",
        "N.SGD(30, 10, 0.03, 0.1, train_data, test_data = test_data)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1, Evaluate : 9315 / 10000\n",
            "Epoch : 2, Evaluate : 9403 / 10000\n",
            "Epoch : 3, Evaluate : 9460 / 10000\n",
            "Epoch : 4, Evaluate : 9501 / 10000\n",
            "Epoch : 5, Evaluate : 9534 / 10000\n",
            "Epoch : 6, Evaluate : 9566 / 10000\n",
            "Epoch : 7, Evaluate : 9576 / 10000\n",
            "Epoch : 8, Evaluate : 9580 / 10000\n",
            "Epoch : 9, Evaluate : 9586 / 10000\n",
            "Epoch : 10, Evaluate : 9576 / 10000\n",
            "Epoch : 11, Evaluate : 9603 / 10000\n",
            "Epoch : 12, Evaluate : 9599 / 10000\n",
            "Epoch : 13, Evaluate : 9601 / 10000\n",
            "Epoch : 14, Evaluate : 9609 / 10000\n",
            "Epoch : 15, Evaluate : 9632 / 10000\n",
            "Epoch : 16, Evaluate : 9605 / 10000\n",
            "Epoch : 17, Evaluate : 9614 / 10000\n",
            "Epoch : 18, Evaluate : 9631 / 10000\n",
            "Epoch : 19, Evaluate : 9622 / 10000\n",
            "Epoch : 20, Evaluate : 9619 / 10000\n",
            "Epoch : 21, Evaluate : 9635 / 10000\n",
            "Epoch : 22, Evaluate : 9622 / 10000\n",
            "Epoch : 23, Evaluate : 9628 / 10000\n",
            "Epoch : 24, Evaluate : 9624 / 10000\n",
            "Epoch : 25, Evaluate : 9629 / 10000\n",
            "Epoch : 26, Evaluate : 9649 / 10000\n",
            "Epoch : 27, Evaluate : 9642 / 10000\n",
            "Epoch : 28, Evaluate : 9629 / 10000\n",
            "Epoch : 29, Evaluate : 9636 / 10000\n",
            "Epoch : 30, Evaluate : 9635 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}