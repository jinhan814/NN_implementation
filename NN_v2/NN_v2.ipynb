{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu1Jb5jpumYj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Sigmoid:\n",
        "    def __call__(self, x):\n",
        "        return 1. / (1. + np.exp(-x))\n",
        "\n",
        "    def deriv(self, x):\n",
        "        return self(x) * (1 - self(x))\n",
        "\n",
        "\n",
        "class ReLU:\n",
        "    def __call__(self, x):\n",
        "        return np.maximum(0, x)\n",
        "    \n",
        "    def deriv(self, x):\n",
        "        return (x > 0).astype(np.float32)\n",
        "\n",
        "\n",
        "class LeakyReLU:\n",
        "    def __call__(self, x):\n",
        "        ret = x\n",
        "        ret[ret < 0] *= 0.01\n",
        "        return ret.astype(np.float32)\n",
        "\n",
        "    def deriv(self, x):\n",
        "        ret = x\n",
        "        ret[ret < 0] = -0.01\n",
        "        ret[ret > 0] = 1.\n",
        "        return ret.astype(np.float32)\n",
        "\n",
        "\n",
        "class MSE:\n",
        "    def __call__(self, res, y):\n",
        "        return sum((i - j) * (i - j) for i, j in zip(res, y))\n",
        "\n",
        "    def deriv(self, res, y, z, activation_f):\n",
        "        return (res - y) * activation_f.deriv(z)\n",
        "\n",
        "\n",
        "class CrossEntropy:\n",
        "    def __call__(self, res, y):\n",
        "        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
        "    \n",
        "    def deriv(self, res, y, z, activation_f):\n",
        "        return res - y\n",
        "\n",
        "\n",
        "class Network:\n",
        "    def __init__(self, shape, activation_f=ReLU(), cost_f=CrossEntropy()):\n",
        "        np.random.seed(2048)\n",
        "        self.shape = shape\n",
        "        self.w = [np.random.uniform(-(6/x)**0.5, (6/x)**0.5, x*y).reshape(y, x) for x, y in zip(shape[:-1], shape[1:])]\n",
        "        self.b = [np.random.uniform(-(6/x)**0.5, (6/x)**0.5, 1*y).reshape(y, 1) for x, y in zip(shape[:-1], shape[1:])]\n",
        "        self.activation_f = activation_f\n",
        "        self.cost_f = cost_f\n",
        "\n",
        "    def forward(self, x):\n",
        "        ret = x.reshape(-1, 1)\n",
        "        for w, b in zip(self.w, self.b):\n",
        "            ret = self.activation_f(np.dot(w, ret) + b)\n",
        "        return ret.reshape(-1)\n",
        "\n",
        "    def backward(self, _x, _y):\n",
        "        dw = [np.zeros(w.shape) for w in self.w]\n",
        "        db = [np.zeros(b.shape) for b in self.b]\n",
        "        x, y = _x.reshape(-1, 1), _y.reshape(-1, 1)\n",
        "        a, z = [x], []\n",
        "\n",
        "        for w, b in zip(self.w, self.b):\n",
        "            x = np.dot(w, x) + b\n",
        "            z.append(x)\n",
        "            x = self.activation_f(x)\n",
        "            a.append(x)\n",
        "\n",
        "        dz = self.cost_f.deriv(a[-1], y, z[-1], self.activation_f)\n",
        "        dw[-1] = np.dot(dz, a[-2].transpose())\n",
        "        db[-1] = dz\n",
        "\n",
        "        for i in range(2, len(self.shape)):\n",
        "            dz = np.dot(self.w[-(i - 1)].transpose(), dz) * self.activation_f.deriv(z[-i])\n",
        "            dw[-i] = np.dot(dz, a[-(i + 1)].transpose())\n",
        "            db[-i] = dz\n",
        "\n",
        "        return (dw, db)\n",
        "\n",
        "    def update(self, batch, lr, lmbda):\n",
        "        dw = [np.zeros(w.shape) for w in self.w]\n",
        "        db = [np.zeros(b.shape) for b in self.b]\n",
        "\n",
        "        for x, y in batch:\n",
        "            _dw, _db = self.backward(x, y)\n",
        "            dw = [w + _w for w, _w in zip(dw, _dw)]\n",
        "            db = [b + _b for b, _b in zip(db, _db)]\n",
        "\n",
        "        self.w = [(1 - lr * (lmbda / len(train_data))) * w - (lr / len(batch)) * _w for w, _w in zip(self.w, dw)]\n",
        "        self.b = [b - (lr / len(batch)) * _b for b, _b in zip(self.b, db)]\n",
        "\n",
        "    def SGD(self, epochs, batch_size, lr, lmbda, train_data, test_data=None):\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            np.random.shuffle(train_data)\n",
        "            batchs = [train_data[i:i + batch_size] for i in range(0, len(train_data), batch_size)]\n",
        "            for batch in batchs: self.update(batch, lr, lmbda)\n",
        "            if test_data: print(f\"Epoch : {epoch}, Evaluate : {self.evaluate(test_data)} / {len(test_data)}\")\n",
        "            else: print(f\"Epoch : {epoch}\")\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        ret = sum(int(np.argmax(self.forward(x)) == np.argmax(y)) for x, y in test_data)\n",
        "        return ret\n",
        "\n",
        "    def Calc(self, x):\n",
        "        y = self.forward(x)\n",
        "        return np.argmax(y)\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vVQ5ytITzfN"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "train_data = np.concatenate((y_train, x_train), axis = 1)\n",
        "test_data = np.concatenate((y_test, x_test), axis = 1)\n",
        "\n",
        "def __Conv(data, n=10):\n",
        "    x = data[1:].astype(np.float32) / 255\n",
        "    y = np.array([int(i == data[0]) for i in range(n)]).astype(np.float32)\n",
        "    return (x, y)\n",
        "\n",
        "def Conv(data):\n",
        "    ret = [*data]\n",
        "    for i in range(len(ret)):\n",
        "        ret[i] = __Conv(ret[i])\n",
        "    return ret\n",
        "\n",
        "train_data = Conv(train_data)\n",
        "test_data  = Conv(test_data)\n"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJJfnmZIPCBh",
        "outputId": "40b40afd-e5f1-4951-fd16-9589acaa85cb"
      },
      "source": [
        "N = Network([784, 28, 28, 10])\n",
        "N.SGD(30, 10, 0.03, 0.1, train_data, test_data = test_data)\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1, Evaluate : 9381 / 10000\n",
            "Epoch : 2, Evaluate : 9470 / 10000\n",
            "Epoch : 3, Evaluate : 9514 / 10000\n",
            "Epoch : 4, Evaluate : 9526 / 10000\n",
            "Epoch : 5, Evaluate : 9555 / 10000\n",
            "Epoch : 6, Evaluate : 9585 / 10000\n",
            "Epoch : 7, Evaluate : 9578 / 10000\n",
            "Epoch : 8, Evaluate : 9580 / 10000\n",
            "Epoch : 9, Evaluate : 9623 / 10000\n",
            "Epoch : 10, Evaluate : 9624 / 10000\n",
            "Epoch : 11, Evaluate : 9646 / 10000\n",
            "Epoch : 12, Evaluate : 9627 / 10000\n",
            "Epoch : 13, Evaluate : 9650 / 10000\n",
            "Epoch : 14, Evaluate : 9644 / 10000\n",
            "Epoch : 15, Evaluate : 9640 / 10000\n",
            "Epoch : 16, Evaluate : 9664 / 10000\n",
            "Epoch : 17, Evaluate : 9666 / 10000\n",
            "Epoch : 18, Evaluate : 9671 / 10000\n",
            "Epoch : 19, Evaluate : 9680 / 10000\n",
            "Epoch : 20, Evaluate : 9672 / 10000\n",
            "Epoch : 21, Evaluate : 9662 / 10000\n",
            "Epoch : 22, Evaluate : 9675 / 10000\n",
            "Epoch : 23, Evaluate : 9667 / 10000\n",
            "Epoch : 24, Evaluate : 9689 / 10000\n",
            "Epoch : 25, Evaluate : 9667 / 10000\n",
            "Epoch : 26, Evaluate : 9668 / 10000\n",
            "Epoch : 27, Evaluate : 9683 / 10000\n",
            "Epoch : 28, Evaluate : 9680 / 10000\n",
            "Epoch : 29, Evaluate : 9689 / 10000\n",
            "Epoch : 30, Evaluate : 9697 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}